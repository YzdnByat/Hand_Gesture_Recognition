# Hand Gesture Recognition with Mediapipe & LSTM

This project implements a **real-time hand gesture recognition system** using **Mediapipe** for hand landmark detection and an **LSTM deep learning model** for sequence classification.  
The system recognizes five common gestures and maps them to multimedia control actions such as volume adjustment, video navigation, and play/pause.

---

## âœ¨ Features
- Extracts **21 hand landmarks** (x, y, z coordinates) from each video frame using Mediapipe.
- Builds temporal sequences of 30 frames to capture motion dynamics.
- Trains a **stacked LSTM network** with dropout and dense layers for gesture classification.
- Achieves **97â€“98% accuracy** on validation sets.
- Real-time **inference pipeline** with webcam input.
- Uses **PyAutoGUI** to trigger system commands:
  - ğŸ‘ Thumbs Up â†’ Volume Up  
  - ğŸ‘ Thumbs Down â†’ Volume Down  
  - ğŸ‘‹ Left Swipe â†’ Rewind video  
  - ğŸ‘‰ Right Swipe â†’ Forward video  
  - âœŠ Fist (Stop gesture) â†’ Play/Pause  

---

## ğŸ“‚ Project Structure
Hand_Gesture_Recognition/
â”‚
â”œâ”€â”€ Hand_Gesture_Recognition.ipynb # Main Jupyter Notebook
â”œâ”€â”€ Hand_Gesture_Recognition.pdf # Full project report
â”œâ”€â”€ models/ # Trained LSTM models (saved .h5 files)
â”œâ”€â”€ gifs/ # Demo animations
â””â”€â”€ README.md

